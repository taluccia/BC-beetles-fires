---
title: "BRT 3 Category FWI"
author: "Anna Talucci"
date: "7/31/2021"
output: html_document
---





# Overview
NEW SAMPLE!!!! Split FWI in to 3 categories
## Notes

9-2-2019 Run wi sampling from updated gee code that should match the 5-15-2019 version.

Final Models
Full Model
Simple Model


--Beetle vs. Fuels

Boosted Regression Trees in R 
Note: this is a cut-down version of a tutorial prepared by Jane Elith and John Leathwick
Adapted by Chris Dunn for fire risk assessment
Adapted by Garrett Meigs for analysis of fire refugia
Complementary to Krawchuk et al. 2016 Ecosphere scripts



# Clear workspace

```{r}
rm(list=ls()) 
```


## Set libraries
```{r include=FALSE}

library(devtools)
library(gbm)
library(foreign)
library(dismo)
library(dplyr)
library(splines)
library(ggplot2)
```

## BRT functions 
These are provided in a file such as ?brt.functions.R? and can be loaded into R using the source command, e.g.:
```{r}
source("../function/brt.functions.R")
```

# Data
```{r}
model.data = read.csv("../data/CombinedData/CombineDataCat3FWI.csv", header=TRUE, sep = ",", strip.white = TRUE)
```

```{r}
head(model.data)
```

## Select Columns 
Select variable columns
*  dndmi 
*  elevation
*  fwi 
*  ndviprefire

Mutate to add columns for classifying FWI and RdNBR
FWI lo=1, hi=2 
2 is anything greater then 29 and 1 is anything less than or equal to 29
Rdnbr low = 0, high=1


```{r}
data_full = model.data %>%
  dplyr::select(dndmi, elevation, fwi, ndviprefire, rdnbr_class)
data_full
```

```{r}

data_ben = model.data %>%
  filter(fwi_cat == "benign") %>%
  dplyr::select(dndmi, elevation, fwi, ndviprefire, rdnbr_class)
data_ben
```

```{r}

data_mod = model.data %>%
  filter(fwi_cat == "moderate") %>%
  dplyr::select(dndmi, elevation, fwi, ndviprefire, rdnbr_class)
data_mod
```


```{r}

data_ext= model.data %>%
  filter(fwi_cat == "extreme") %>%
  dplyr::select(dndmi, elevation, fwi, ndviprefire, rdnbr_class)
data_ext
```


# Model 1 
No split for weather four variable outbreak, prefire veg, fwi, elevation

```{r}
head(data_full)
```

```{r}
set.seed(15) # Set random seed
brt.model1 <- gbm.step(data=data_full,
    gbm.x = c(1,2,3,4), 
    gbm.y = 5,
    family = "bernoulli",
    tree.complexity = 5,
    learning.rate = 0.001,
    bag.fraction = 0.5)
```

### Get info in model output
```{r}
summary(brt.model1,
        cBars=length(brt.model1$var.names),
        n.trees=brt.model1$n.trees,
        plotit=TRUE,
        order=TRUE,
        method=relative.influence,
        normalize=FALSE)
```

https://towardsdatascience.com/understanding-gradient-boosting-machines-9be756fe76ab
```{r}
ntree_opt_cv = gbm.perf(brt.model1, method = "cv")
```

```{r}
( ntree_opt_oob = gbm.perf(brt.model1, method = "OOB") )
```

### Save model outputs as external object for mapping later or posterity

```{r}
save(brt.model1, file = "../outputs/BRTmodelsFWI3/BRT1_model.rda")
```

```{r eval=FALSE, include=FALSE}
load(file = "../outputs/BRTmodelsFWI3/BRT1_model.rda")
```

### Relative influence of predictors as part of summary gbm - for model assessment
```{r}
relative.influence(brt.model1, scale=TRUE, sort=TRUE)
```

Notes: permutation.test.gbm(brt.model, n.trees=brt.model$n.trees); This method randomly permutes each predictor variable at a time and computes the associated reduction in predictive performance, similar to random forests. gbm.loss(y,f,w,offset,dist,baseline, group, max.rank)

### Plotting (Anna Added)
```{r}
gbm.plot(brt.model1, smooth=TRUE, write.title = TRUE, y.label="Fitted function", x.label="")
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT1_plots.pdf")
dev.off()
```
```{r}
gbm.plot.fits(brt.model1)
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT1_fits.pdf")
dev.off()
```

```{r}
find.int = gbm.interactions(brt.model1)
find.int$rank.list
find.int$interactions
```





## Calculate outputs stats 
- Sandra Haire calculations and file export below from Krawchuk et al. (2016) Ecosphere
Note that these calculatins are not the same as the default outputss from the BRT code.
```{r}
tot.n=nrow(data_full)
y.perc=round(nrow(data_full[data_full$yvar==1,])/tot.n,2)
vnames=row.names(brt.model1$contributions)
rel.inf=round(brt.model1$contributions[,2],2) # variable num, from df and %contrib for each
perc.dev.expl=round(1-(brt.model1$self.statistics$mean.resid/brt.model1$self.statistics$mean.null),2)
roc.mean=round(mean(brt.model1$cv.roc.matrix),2)
cv.dev.mean=round(brt.model1$cv.statistics$deviance.mean,2)
cv.cor.mean=round(brt.model1$cv.statistics$correlation.mean,2)
cv.discrim.mean=round(brt.model1$cv.statistics$discrimination.mean,2)
```

```{r}
BRT.model1.sum=data.frame(tot.n, y.perc, brt.model1$n.trees, perc.dev.expl, roc.mean, cv.dev.mean, cv.cor.mean, cv.discrim.mean)
write.csv(BRT.model1.sum, '../outputs/BRTmodelsFWI3/BRT1_sum.csv', row.names = F)
BRT.model1.relinf=data.frame(rel.inf, vnames)
write.csv(BRT.model1.relinf, '../outputs/BRTmodelsFWI3/BRT1_relinf.csv', row.names = F)
```

```{r}
BRT.model1.sum
```

```{r}
BRT.model1.relinf
```






# Model 2 
Split FWI - FWI HI 
Run the BRT model
with explanatory variables: 
*  dndmi (15)
*  elevation(17)
*  fwi (18)
*  ndviprefire (21)
Response varaible
*  rdnbr_class
```{r}
head(data_ext)
```

```{r}
set.seed(15) # Set random seed
brt.model2 <- gbm.step(data=data_ext,
    gbm.x = c(1,2,3,4), 
    gbm.y = 5,
    family = "bernoulli",
    tree.complexity = 5,
    learning.rate = 0.001,
    bag.fraction = 0.5)
```

### Get info in model outputs
```{r}
summary(brt.model2,
        cBars=length(brt.model2$var.names),
        n.trees=brt.model2$n.trees,
        plotit=TRUE,
        order=TRUE,
        method=relative.influence,
        normalize=FALSE)
```

### Save model outputs as external object for mapping later or posterity

```{r}
save(brt.model2, file = "../outputs/BRTmodelsFWI3/BRT2_model.rda")
```

```{r eval=FALSE, include=FALSE}
load(file = "../outputs/BRTmodelsFWI3/BRT2_model.rda")
```

### Relative influence of predictors as part of summary gbm - for model assessment
```{r}
relative.influence(brt.model2, scale=TRUE, sort=TRUE)
```

Notes: permutation.test.gbm(brt.model, n.trees=brt.model$n.trees); This method randomly permutes each predictor variable at a time and computes the associated reduction in predictive performance, similar to random forests. gbm.loss(y,f,w,offset,dist,baseline, group, max.rank)

### Plotting (Anna Added)
```{r}
gbm.plot(brt.model2, smooth=TRUE, write.title = FALSE)
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT2_plots.pdf")
dev.off()
```
```{r}
gbm.plot.fits(brt.model2)
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT2_fits.pdf")
dev.off()
```

```{r}
find.int = gbm.interactions(brt.model2)
find.int$rank.list
find.int$interactions
```

## Calculate outputs stats 
- Sandra Haire calculations and file export below from Krawchuk et al. (2016) Ecosphere
Note that these calculatins are not the same as the default outputs from the BRT code.
```{r}
tot.n=nrow(data_ext)
y.perc=round(nrow(data_ext[data_ext$yvar==1,])/tot.n,2)
vnames=row.names(brt.model2$contributions)
rel.inf=round(brt.model2$contributions[,2],2) # variable num, from df and %contrib for each
perc.dev.expl=round(1-(brt.model2$self.statistics$mean.resid/brt.model2$self.statistics$mean.null),2)
roc.mean=round(mean(brt.model2$cv.roc.matrix),2)
cv.dev.mean=round(brt.model2$cv.statistics$deviance.mean,2)
cv.cor.mean=round(brt.model2$cv.statistics$correlation.mean,2)
cv.discrim.mean=round(brt.model2$cv.statistics$discrimination.mean,2)
```

```{r}
BRT.model2.sum=data.frame(tot.n, y.perc, brt.model2$n.trees, perc.dev.expl, roc.mean, cv.dev.mean, cv.cor.mean, cv.discrim.mean)
write.csv(BRT.model2.sum, '../outputs/BRTmodelsFWI3/BRT2_sum.csv', row.names = F)
BRT.model2.relinf=data.frame(rel.inf, vnames)
write.csv(BRT.model2.relinf, '../outputs/BRTmodelsFWI3/BRT2_relinf.csv', row.names = F)
```

```{r}
BRT.model2.sum
```

```{r}
BRT.model2.relinf
```

# Model 3: Split FWI - FWI Lo 
```{r}
head(data_mod)
```

```{r}
set.seed(15) # Set random seed
brt.model3 <- gbm.step(data=data_mod,
    gbm.x = c(1,2,3,4), 
    gbm.y = 5,
    family = "bernoulli",
    tree.complexity = 5,
    learning.rate = 0.001,
    bag.fraction = 0.5)
```

### Get info in model outputs
```{r}
summary(brt.model3,
        cBars=length(brt.model3$var.names),
        n.trees=brt.model3$n.trees,
        plotit=TRUE,
        order=TRUE,
        method=relative.influence,
        normalize=FALSE)
```

### Save model outputs as external object for mapping later or posterity

```{r}
save(brt.model3, file = "../outputs/BRTmodelsFWI3/BRT3_model.rda")
```

```{r eval=FALSE, include=FALSE}
load(file = "../outputs/BRTmodelsFWI3/BRT3_model.rda")
```

### Relative influence of predictors as part of summary gbm - for model assessment
```{r}
relative.influence(brt.model3, scale=TRUE, sort=TRUE)
```

Notes: permutation.test.gbm(brt.model, n.trees=brt.model$n.trees); This method randomly permutes each predictor variable at a time and computes the associated reduction in predictive performance, similar to random forests. gbm.loss(y,f,w,offset,dist,baseline, group, max.rank)

### Plotting (Anna Added)
```{r}
gbm.plot(brt.model3, smooth=TRUE, write.title = FALSE)
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT3_plots.pdf")
dev.off()
```
```{r}
gbm.plot.fits(brt.model3)
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT3_fits.pdf")
dev.off()
```

```{r}
find.int = gbm.interactions(brt.model3)
find.int$rank.list
find.int$interactions
```

## Calculate outputs stats 
- Sandra Haire calculations and file export below from Krawchuk et al. (2016) Ecosphere
Note that these calculatins are not the same as the default outputs from the BRT code.
```{r}
tot.n=nrow(data_mod)
y.perc=round(nrow(data_mod[data_mod$yvar==1,])/tot.n,2)
vnames=row.names(brt.model3$contributions)
rel.inf=round(brt.model3$contributions[,2],2) # variable num, from df and %contrib for each
perc.dev.expl=round(1-(brt.model3$self.statistics$mean.resid/brt.model3$self.statistics$mean.null),2)
roc.mean=round(mean(brt.model3$cv.roc.matrix),2)
cv.dev.mean=round(brt.model3$cv.statistics$deviance.mean,2)
cv.cor.mean=round(brt.model3$cv.statistics$correlation.mean,2)
cv.discrim.mean=round(brt.model3$cv.statistics$discrimination.mean,2)
```

```{r}
BRT.model3.sum=data.frame(tot.n, y.perc, brt.model3$n.trees, perc.dev.expl, roc.mean, cv.dev.mean, cv.cor.mean, cv.discrim.mean)
write.csv(BRT.model3.sum, '../outputs/BRTmodelsFWI3/BRT3_sum.csv', row.names = F)
BRT.model3.relinf=data.frame(rel.inf, vnames)
write.csv(BRT.model3.relinf, '../outputs/BRTmodelsFWI3/BRT3_relinf.csv', row.names = F)
```

```{r}
BRT.model3.sum
```

```{r}
BRT.model3.relinf
```

# Model 4
```{r}
head(data_ben)
```

```{r}
set.seed(15) # Set random seed
brt.model4 <- gbm.step(data=data_ben,
    gbm.x = c(1,2,3,4), 
    gbm.y = 5,
    family = "bernoulli",
    tree.complexity = 5,
    learning.rate = 0.001,
    bag.fraction = 0.5)
```

### Get info in model outputs
```{r}
summary(brt.model4,
        cBars=length(brt.model4$var.names),
        n.trees=brt.model4$n.trees,
        plotit=TRUE,
        order=TRUE,
        method=relative.influence,
        normalize=FALSE)
```

### Save model outputs as external object for mapping later or posterity

```{r}
save(brt.model4, file = "../outputs/BRTmodelsFWI3/BRT4_model.rda")
```

```{r eval=FALSE, include=FALSE}
load(file = "../outputs/BRTmodelsFWI3/BRT4_model.rda")
```

### Relative influence of predictors as part of summary gbm - for model assessment
```{r}
relative.influence(brt.model4, scale=TRUE, sort=TRUE)
```

Notes: permutation.test.gbm(brt.model, n.trees=brt.model$n.trees); This method randomly permutes each predictor variable at a time and computes the associated reduction in predictive performance, similar to random forests. gbm.loss(y,f,w,offset,dist,baseline, group, max.rank)

### Plotting (Anna Added)
```{r}
gbm.plot(brt.model4, smooth=TRUE, write.title = FALSE)
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT4_plots.pdf")
dev.off()
```
```{r}
gbm.plot.fits(brt.model4)
dev.print(pdf, "../outputs/BRTmodelsFWI3/BRT4_fits.pdf")
dev.off()
```

```{r}
find.int = gbm.interactions(brt.model4)
find.int$rank.list
find.int$interactions
```

## Calculate outputs stats 
- Sandra Haire calculations and file export below from Krawchuk et al. (2016) Ecosphere
Note that these calculatins are not the same as the default outputs from the BRT code.
```{r}
tot.n=nrow(data_ben)
y.perc=round(nrow(data_ben[data_ben$yvar==1,])/tot.n,2)
vnames=row.names(brt.model4$contributions)
rel.inf=round(brt.model4$contributions[,2],2) # variable num, from df and %contrib for each
perc.dev.expl=round(1-(brt.model4$self.statistics$mean.resid/brt.model4$self.statistics$mean.null),2)
roc.mean=round(mean(brt.model4$cv.roc.matrix),2)
cv.dev.mean=round(brt.model4$cv.statistics$deviance.mean,2)
cv.cor.mean=round(brt.model4$cv.statistics$correlation.mean,2)
cv.discrim.mean=round(brt.model4$cv.statistics$discrimination.mean,2)
```

```{r}
BRT.model4.sum=data.frame(tot.n, y.perc, brt.model4$n.trees, perc.dev.expl, roc.mean, cv.dev.mean, cv.cor.mean, cv.discrim.mean)
write.csv(BRT.model4.sum, '../outputs/BRTmodelsFWI3/BRT4_sum.csv', row.names = F)
BRT.model4.relinf=data.frame(rel.inf, vnames)
write.csv(BRT.model4.relinf, '../outputs/BRTmodelsFWI3/BRT4_relinf.csv', row.names = F)
```

```{r}
BRT.model4.sum
```

```{r}
BRT.model4.relinf
```

